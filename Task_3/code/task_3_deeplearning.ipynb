{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments of different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Experimental Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import Preprocess\n",
    "import platform\n",
    "\n",
    "\n",
    "\n",
    "file_path = os.path.abspath(os.path.dirname(os.path.dirname(os.path.abspath(''))))\n",
    "\n",
    "if platform.system().lower() == 'windows':\n",
    "    print(\"windows\")\n",
    "    dataset_X = np.load(file_path + \"\\Task_3\\data\\dataset_X.npy\")\n",
    "    dataset_Y = np.load(file_path + \"\\Task_3\\data\\dataset_Y.npy\")\n",
    "elif platform.system().lower() == 'linux':\n",
    "    print(\"linux\")\n",
    "    dataset_X = np.load(file_path + \"/Task_3/data/dataset_X.npy\")\n",
    "    dataset_Y = np.load(file_path + \"/Task_3/data/dataset_Y.npy\")\n",
    "\n",
    "\n",
    "data_X = []\n",
    "data_Y = []\n",
    "\n",
    "num = 24\n",
    "\n",
    "for i in range(0, len(dataset_X)-num, 24):\n",
    "    data_X.append(dataset_X[i:i+num])\n",
    "    data_Y.append(dataset_Y[i:i+num])\n",
    "    \n",
    "data_X = np.array(data_X)\n",
    "data_Y = np.array(data_Y)\n",
    "\n",
    "train_X = data_X[:1200]\n",
    "train_Y = data_Y[:1200]\n",
    "test_X = data_X[1200:]\n",
    "test_Y = data_Y[1200:]\n",
    "\n",
    "Preprocess.save_as_npy(train_X, train_Y, test_X, test_Y)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import platform\n",
    "\n",
    "if platform.system().lower() == 'windows':\n",
    "    print(\"windows\")\n",
    "    train_X = np.load(file_path + '\\Task_3\\data\\\\train_X.npy')\n",
    "    train_Y = np.load(file_path + '\\Task_3\\data\\\\train_Y.npy')\n",
    "    test_X = np.load(file_path + '\\Task_3\\data\\\\test_X.npy')\n",
    "    test_Y = np.load(file_path + '\\Task_3\\data\\\\test_Y.npy')\n",
    "elif platform.system().lower() == 'linux':\n",
    "    print(\"linux\")\n",
    "    train_X = np.load(file_path + '/Task_3/data/train_X.npy')\n",
    "    train_Y = np.load(file_path + '/Task_3/data/train_Y.npy')\n",
    "    test_X = np.load(file_path + '/Task_3/data/test_X.npy')\n",
    "    test_Y = np.load(file_path + '/Task_3/data/test_Y.npy')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.customed_dataset import customed_dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "file_path = os.path.abspath(os.path.dirname(os.path.dirname(os.path.abspath(''))))\n",
    "\n",
    "# dataset_X = np.load(file_path + \"\\Task_2\\data\\\\dataset_X.npy\")\n",
    "# dataset_Y = np.load(file_path + \"\\Task_2\\data\\\\dataset_Y.npy\")\n",
    "\n",
    "# dataset = customed_dataset(dataset_X, dataset_Y)\n",
    "\n",
    "# train_size = int(0.8 * len(dataset))\n",
    "# test_size = len(dataset) - train_size\n",
    "# train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_dataset = customed_dataset(train_X, train_Y)\n",
    "test_dataset = customed_dataset(test_X, test_Y)\n",
    "\n",
    "training_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=0)\n",
    "validation_loader = torch.utils.data.DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test of Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from models import lstm\n",
    "from models import gru\n",
    "from models import transformer\n",
    "\n",
    "file_path = os.path.abspath('') \n",
    "\n",
    "### lstm\n",
    "model_lstm = lstm.lstm_model()\n",
    "model_lstm.load_state_dict(torch.load(file_path + '/models/LSTM_model_average'))\n",
    "model_lstm.eval()\n",
    "\n",
    "### gru\n",
    "model_gru = gru.gru_model()\n",
    "model_gru.load_state_dict(torch.load(file_path + '/models/GRU_model_average'))\n",
    "model_gru.eval()\n",
    "\n",
    "### transformer\n",
    "model_transformer = transformer.transformer_model()\n",
    "model_transformer.load_state_dict(torch.load(file_path + '/models/Transformer_model_average'))\n",
    "model_transformer.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lstm test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import mean_squared_error #均方误差\n",
    "from sklearn.metrics import mean_absolute_error #平方绝对误差\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "lstm_predictions = []\n",
    "lstm_targets = []\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "for batch_idx, (data, target) in enumerate(validation_loader):\n",
    "    lstm_predictions.append(model_lstm.forward(data.float()).detach().numpy().tolist())\n",
    "    lstm_targets.append(target.numpy().tolist())\n",
    "lstm_predictions = torch.squeeze(torch.tensor(lstm_predictions)).reshape(-1).numpy()\n",
    "lstm_targets = torch.squeeze(torch.tensor(lstm_targets)).reshape(-1).numpy()\n",
    "\n",
    "print(mean_squared_error(lstm_targets, lstm_predictions))\n",
    "print(mean_absolute_error(lstm_targets, lstm_predictions))\n",
    "print(r2_score(lstm_targets, lstm_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gru test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import mean_squared_error #均方误差\n",
    "from sklearn.metrics import mean_absolute_error #平方绝对误差\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "model_gru = model_gru.cuda()\n",
    "\n",
    "gru_predictions = []\n",
    "gru_targets = []\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=0)\n",
    "\n",
    "for batch_idx, (data, target) in enumerate(validation_loader):\n",
    "    if len(data) != 4:\n",
    "        continue\n",
    "    gru_predictions.append(model_gru.forward(data.float().cuda()).cpu().detach().numpy().tolist())\n",
    "    gru_targets.append(target.numpy().tolist())\n",
    "gru_predictions = torch.squeeze(torch.tensor(gru_predictions)).reshape(-1).numpy()\n",
    "gru_targets = torch.squeeze(torch.tensor(gru_targets)).reshape(-1).numpy()\n",
    "\n",
    "print(mean_squared_error(gru_targets, gru_predictions))\n",
    "print(mean_absolute_error(gru_targets, gru_predictions))\n",
    "print(r2_score(gru_targets, gru_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import mean_squared_error #均方误差\n",
    "from sklearn.metrics import mean_absolute_error #平方绝对误差\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "model_transformer = model_transformer.cuda()\n",
    "\n",
    "transformer_predictions = []\n",
    "transformer_targets = []\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=0)\n",
    "\n",
    "for batch_idx, (data, target) in enumerate(validation_loader):\n",
    "    if len(data) != 4:\n",
    "        continue\n",
    "    transformer_predictions.append(model_transformer.forward(data.float().cuda()).cpu().detach().numpy().tolist())\n",
    "    transformer_targets.append(target.numpy().tolist())\n",
    "transformer_predictions = torch.squeeze(torch.tensor(transformer_predictions)).reshape(-1).numpy()\n",
    "transformer_targets = torch.squeeze(torch.tensor(transformer_targets)).reshape(-1).numpy()\n",
    "\n",
    "print(mean_squared_error(transformer_targets, transformer_predictions))\n",
    "print(mean_absolute_error(transformer_targets, transformer_predictions))\n",
    "print(r2_score(transformer_targets, transformer_predictions))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.6.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
